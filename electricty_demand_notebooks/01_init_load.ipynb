{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca8c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the combination process...\n",
      "Created directory: ../data/electricity/processed/\n",
      "Found 25 CSV files to combine.\n",
      "Reading ../data/electricity/demanddata_2001.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2002.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2003.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2004.csv...\n",
      "    ...found 17568 rows.\n",
      "Reading ../data/electricity/demanddata_2005.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2006.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2007.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2008.csv...\n",
      "    ...found 17568 rows.\n",
      "Reading ../data/electricity/demanddata_2009.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2010.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2011.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2012.csv...\n",
      "    ...found 17568 rows.\n",
      "Reading ../data/electricity/demanddata_2013.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2014.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2015.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2016.csv...\n",
      "    ...found 17568 rows.\n",
      "Reading ../data/electricity/demanddata_2017.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2018.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2019.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2020.csv...\n",
      "    ...found 17568 rows.\n",
      "Reading ../data/electricity/demanddata_2021.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2022.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2023.csv...\n",
      "    ...found 17520 rows.\n",
      "Reading ../data/electricity/demanddata_2024.csv...\n",
      "    ...found 17568 rows.\n",
      "Reading ../data/electricity/demanddata_2025.csv...\n",
      "    ...found 13822 rows.\n",
      "Concatenating all DataFrames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "/var/folders/6z/vs2gqd6s6zx7b6vqyq8nbwrh0000gn/T/ipykernel_77781/3228907745.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VALIDATION ---\n",
      "Total rows read from all CSVs: 434590\n",
      "Total rows in combined DataFrame: 434590\n",
      "✅ Success: Row counts match!\n",
      "--------------------\n",
      "\n",
      "DataFrame info after combining:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 434590 entries, 0 to 434589\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   SETTLEMENT_DATE            434590 non-null  datetime64[ns]\n",
      " 1   SETTLEMENT_PERIOD          434590 non-null  object        \n",
      " 2   ND                         434590 non-null  object        \n",
      " 3   TSD                        364462 non-null  float32       \n",
      " 4   ENGLAND_WALES_DEMAND       434590 non-null  float32       \n",
      " 5   EMBEDDED_WIND_GENERATION   329422 non-null  float32       \n",
      " 6   EMBEDDED_WIND_CAPACITY     329422 non-null  float32       \n",
      " 7   EMBEDDED_SOLAR_GENERATION  294334 non-null  float32       \n",
      " 8   EMBEDDED_SOLAR_CAPACITY    294334 non-null  float32       \n",
      " 9   NON_BM_STOR                434590 non-null  int64         \n",
      " 10  PUMP_STORAGE_PUMPING       434590 non-null  int64         \n",
      " 11  SCOTTISH_TRANSFER          48910 non-null   float64       \n",
      " 12  IFA_FLOW                   434590 non-null  int64         \n",
      " 13  IFA2_FLOW                  294334 non-null  float64       \n",
      " 14  BRITNED_FLOW               294334 non-null  float64       \n",
      " 15  MOYLE_FLOW                 364462 non-null  float64       \n",
      " 16  EAST_WEST_FLOW             294334 non-null  float64       \n",
      " 17  NEMO_FLOW                  294334 non-null  float64       \n",
      " 18  NSL_FLOW                   119038 non-null  float64       \n",
      " 19  ELECLINK_FLOW              119038 non-null  float64       \n",
      " 20  VIKING_FLOW                119038 non-null  float64       \n",
      " 21  GREENLINK_FLOW             119038 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float32(6), float64(10), int64(3), object(2)\n",
      "memory usage: 99.8 MB\n",
      "Saving combined data to ../data/electricity/processed/demanddata_combined.parquet...\n",
      "✅ Successfully created combined Parquet file!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"Starting the combination process...\")\n",
    "\n",
    "# 1. Define your paths\n",
    "source_data_path = '../data/electricity/'\n",
    "output_folder = '../data/electricity/processed/'\n",
    "output_parquet_path = os.path.join(output_folder, 'demanddata_combined.parquet')\n",
    "\n",
    "# --- Define your dtypes ---\n",
    "data_types = {\n",
    "    'SETTLEMENT_PERIOD': 'category',\n",
    "    'ND': 'category',\n",
    "    'TSD': 'float32',\n",
    "    'ENGLAND_WALES_DEMAND': 'float32',\n",
    "    'EMBEDDED_WIND_GENERATION': 'float32',\n",
    "    'EMBEDDED_SOLAR_GENERATION': 'float32',\n",
    "    'EMBEDDED_WIND_CAPACITY': 'float32',\n",
    "    'EMBEDDED_SOLAR_CAPACITY': 'float32',\n",
    "    # Add any other columns you want to specify...\n",
    "}\n",
    "parse_dates = ['SETTLEMENT_DATE']\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"Created directory: {output_folder}\")\n",
    "\n",
    "# 2. Find all the CSV files\n",
    "csv_pattern = os.path.join(source_data_path, \"demanddata_*.csv\")\n",
    "all_csv_files = glob.glob(csv_pattern)\n",
    "all_csv_files.sort()\n",
    "\n",
    "if not all_csv_files:\n",
    "    print(f\"❌ Error: Found 0 CSV files. Check your path: {csv_pattern}\")\n",
    "else:\n",
    "    print(f\"Found {len(all_csv_files)} CSV files to combine.\")\n",
    "\n",
    "    # 3. Read and collect all DataFrames\n",
    "    dfs_list = []\n",
    "    total_csv_rows = 0  # <--- NEW: Initialize row counter\n",
    "    \n",
    "    for csv_file in all_csv_files:\n",
    "        print(f\"Reading {csv_file}...\")\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                csv_file,\n",
    "                dtype=data_types,\n",
    "                parse_dates=parse_dates,\n",
    "                low_memory=False \n",
    "            )\n",
    "            \n",
    "            # --- NEW: Add rows of this file to the total count ---\n",
    "            current_rows = len(df)\n",
    "            total_csv_rows += current_rows\n",
    "            print(f\"    ...found {current_rows} rows.\")\n",
    "            \n",
    "            dfs_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csv_file}: {e}\")\n",
    "\n",
    "    # 4. Concatenate all DataFrames\n",
    "    if dfs_list:\n",
    "        print(\"Concatenating all DataFrames...\")\n",
    "        combined_df = pd.concat(dfs_list, ignore_index=True)\n",
    "        \n",
    "        # --- NEW: Validation Step ---\n",
    "        print(\"\\n--- VALIDATION ---\")\n",
    "        print(f\"Total rows read from all CSVs: {total_csv_rows}\")\n",
    "        print(f\"Total rows in combined DataFrame: {len(combined_df)}\")\n",
    "        \n",
    "        if total_csv_rows == len(combined_df):\n",
    "            print(\"✅ Success: Row counts match!\")\n",
    "        else:\n",
    "            print(\"❌ Mismatch: Row counts do NOT match! Check your files.\")\n",
    "        print(\"--------------------\\n\")\n",
    "\n",
    "        print(\"DataFrame info after combining:\")\n",
    "        combined_df.info(memory_usage='deep')\n",
    "\n",
    "        # 5. Save the combined DataFrame to a single Parquet file\n",
    "        print(f\"Saving combined data to {output_parquet_path}...\")\n",
    "        combined_df.to_parquet(\n",
    "            output_parquet_path,\n",
    "            engine='pyarrow',\n",
    "            compression='snappy'\n",
    "        )\n",
    "        print(\"✅ Successfully created combined Parquet file!\")\n",
    "    else:\n",
    "        print(\"No data was loaded to concatenate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
