{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ef974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Define Paths and Settings (Confirmed correct via your screenshot) ---\n",
    "print(\"--- Starting Final Data Preparation ---\")\n",
    "csv_file_path = '../data/electricity/price_paid_records.csv' \n",
    "processed_dir = '../data/electricity/processed/' \n",
    "final_parquet_file_path = os.path.join(processed_dir, 'electricity_model_ready.parquet') \n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# --- 3. LOAD THE RAW CSV ---\n",
    "print(f\"1. Loading raw CSV from: {csv_file_path}\")\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        csv_file_path,\n",
    "        parse_dates=['SETTLEMENT_DATE'],\n",
    "        low_memory=False, \n",
    "        engine='c'\n",
    "    )\n",
    "    print(f\"   -> Load successful. Raw records: {len(df):,}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"   -> ERROR: File not found. Path: {csv_file_path}. Aborting.\")\n",
    "    exit()\n",
    "\n",
    "# --- 4. APPLY CONSOLIDATED CLEANING AND FEATURE ENGINEERING ---\n",
    "print(\"\\n2. Applying cleaning and feature engineering...\")\n",
    "\n",
    "# A. Column Renaming (Mandatory Assignment Requirement)\n",
    "def clean_col_name(col):\n",
    "    return col.lower().replace(' ', '_').strip()\n",
    "\n",
    "df.columns = [clean_col_name(col) for col in df.columns]\n",
    "\n",
    "# B. Feature Engineering (Add Year and Rename Date)\n",
    "df['Year'] = df['SETTLEMENT_DATE'].dt.year\n",
    "\n",
    "# C. Handle Outliers (Filtering out non-market sales)\n",
    "# count_low_price = len(df[df['price'] <= 1])\n",
    "# df = df[df['price'] > 1].copy()\n",
    "\n",
    "# print(f\"   -> Removed {count_low_price:,} low-value transactions (Price <= Â£1).\")\n",
    "# print(f\"   -> Cleaned records remaining: {len(df):,}\")\n",
    "\n",
    "# D. Final Column Cleanup (Drop the unique ID column)\n",
    "# df.drop(columns=['transaction_unique_identifier'], inplace=True)\n",
    "# print(\"   -> Columns renamed, sale_year created, and ID dropped.\")\n",
    "\n",
    "# F. Drop redundant columns\n",
    "# cols_to_drop = ['ppd_category_type', 'record_status_-_monthly_file_only']\n",
    "# df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "# print(f\"\\nFinal number of columns: {len(df.columns)}\")\n",
    "\n",
    "# --- 5. FINAL SAVE ---\n",
    "print(\"\\n3. Saving final model-ready file to Parquet...\")\n",
    "df.to_parquet(final_parquet_file_path, index=False)\n",
    "\n",
    "print(\"\\n--- Final Prep Complete! ---\")\n",
    "print(f\"Model-ready data saved to: {final_parquet_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
