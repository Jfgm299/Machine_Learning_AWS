{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbed6354",
   "metadata": {},
   "source": [
    "## 03 - Final Data Preparation Pipeline\n",
    "\n",
    "**Project:** UK Housing Price Paid Records\n",
    "\n",
    "**Purpose:** To serve as the final, clean, and efficient data pipeline. This notebook takes the raw CSV file and applies all the necessary cleaning, renaming, and feature engineering steps (discovered in 02\\_eda.ipynb) to create the ultimate model-ready Parquet file. **NO GRAPHS or analytical prints should be present.**\n",
    "\n",
    "**Team Member(s):** Tymo Verhaegen\n",
    "\n",
    "**Output File:** `../data/housing/processed/price_paid_model_ready.parquet`\n",
    "\n",
    "**Date Last Run:** 06/11/2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ea9adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Data Preparation ---\n",
      "1. Loading raw CSV from: ../data/housing/price_paid_records.csv\n",
      "   -> Load successful. Raw records: 22,489,348\n",
      "\n",
      "2. Applying cleaning and feature engineering...\n",
      "   -> Removed 92 low-value transactions (Price <= £1).\n",
      "   -> Cleaned records remaining: 22,489,256\n",
      "   -> Columns renamed, sale_year created, and ID dropped.\n",
      "\n",
      "- Duration column updated to ordered category: ['Leasehold', 'Freehold'].\n",
      "\n",
      "Final number of columns: 10\n",
      "\n",
      "3. Saving final model-ready file to Parquet...\n",
      "\n",
      "--- Final Prep Complete! ---\n",
      "Model-ready data saved to: ../data/housing/processed/price_paid_model_ready.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Define Paths and Settings (Confirmed correct via your screenshot) ---\n",
    "print(\"--- Starting Final Data Preparation ---\")\n",
    "csv_file_path = '../data/housing/price_paid_records.csv' \n",
    "processed_dir = '../data/housing/processed/' \n",
    "final_parquet_file_path = os.path.join(processed_dir, 'price_paid_model_ready.parquet') \n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# --- 2. Define Optimal Data Types (Essential for performance) ---\n",
    "data_types = {\n",
    "    'Transaction unique identifier': 'string',\n",
    "    'Price': 'int32',  \n",
    "    'Property Type': 'category',\n",
    "    'Old/New': 'category',\n",
    "    'Duration': 'category',\n",
    "    'Town/City': 'category',\n",
    "    'District': 'category',\n",
    "    'County': 'category',\n",
    "    'PPDCategory Type': 'category',\n",
    "    'Record Status - monthly file only': 'category'\n",
    "}\n",
    "\n",
    "# --- 3. LOAD THE RAW CSV ---\n",
    "print(f\"1. Loading raw CSV from: {csv_file_path}\")\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        csv_file_path, \n",
    "        dtype=data_types,\n",
    "        parse_dates=['Date of Transfer'],\n",
    "        low_memory=False, \n",
    "        engine='c'\n",
    "    )\n",
    "    print(f\"   -> Load successful. Raw records: {len(df):,}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"   -> ERROR: File not found. Path: {csv_file_path}. Aborting.\")\n",
    "    exit()\n",
    "\n",
    "# --- 4. APPLY CONSOLIDATED CLEANING AND FEATURE ENGINEERING ---\n",
    "print(\"\\n2. Applying cleaning and feature engineering...\")\n",
    "\n",
    "# A. Column Renaming (Mandatory Assignment Requirement)\n",
    "def clean_col_name(col):\n",
    "    return col.lower().replace(' ', '_').strip()\n",
    "\n",
    "df.columns = [clean_col_name(col) for col in df.columns]\n",
    "\n",
    "# B. Feature Engineering (Add Year and Rename Date)\n",
    "df['sale_year'] = df['date_of_transfer'].dt.year.astype('int16')\n",
    "df.rename(columns={'date_of_transfer': 'sale_date'}, inplace=True)\n",
    "\n",
    "# C. Handle Outliers (Filtering out non-market sales)\n",
    "count_low_price = len(df[df['price'] <= 1])\n",
    "df = df[df['price'] > 1].copy()\n",
    "\n",
    "print(f\"   -> Removed {count_low_price:,} low-value transactions (Price <= £1).\")\n",
    "print(f\"   -> Cleaned records remaining: {len(df):,}\")\n",
    "\n",
    "# D. Final Column Cleanup (Drop the unique ID column)\n",
    "df.drop(columns=['transaction_unique_identifier'], inplace=True)\n",
    "print(\"   -> Columns renamed, sale_year created, and ID dropped.\")\n",
    "\n",
    "# E Set the order for the 'duration' column (Leasehold vs Freehold)\n",
    "duration_mapping = {'L': 'Leasehold', 'F': 'Freehold'}\n",
    "duration_order = ['Leasehold', 'Freehold']\n",
    "\n",
    "df['duration'] = df['duration'].map(duration_mapping)\n",
    "df['duration'] = pd.Categorical(df['duration'], categories=duration_order, ordered=True)\n",
    "print(\"\\n- Duration column updated to ordered category: ['Leasehold', 'Freehold'].\")\n",
    "\n",
    "# F. Drop redundant columns\n",
    "cols_to_drop = ['ppd_category_type', 'record_status_-_monthly_file_only']\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "print(f\"\\nFinal number of columns: {len(df.columns)}\")\n",
    "\n",
    "# --- 5. FINAL SAVE ---\n",
    "print(\"\\n3. Saving final model-ready file to Parquet...\")\n",
    "df.to_parquet(final_parquet_file_path, index=False)\n",
    "\n",
    "print(\"\\n--- Final Prep Complete! ---\")\n",
    "print(f\"Model-ready data saved to: {final_parquet_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
